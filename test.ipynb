{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test\n",
    "from itertools import product\n",
    "from data_structures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-16 11:28:55.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mRunning experiments with 4 different parameter combinations and 1 iterations.\u001b[0m\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[32m2024-02-16 11:28:55.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mTraining model with {'hidden_dim': 32, 'num_conv_layer': 3, 'num_linear_layers': 2, 'conv_type': 'transformer', 'pooling': 'mean', 'batch_size': 128, 'task_type': 'multiclass', 'dataset': 'ieee118'}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/powergraph/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "\u001b[32m2024-02-16 11:28:56.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDataset characteristics: {'num_node_features': 3, 'num_edge_features': 4, 'num_classes': 4, 'unique_labels': [0, 1, 2, 3], 'counts': [10, 876, 301, 13813], 'dataset': 'ieee118'}\u001b[0m\n",
      "\u001b[32m2024-02-16 11:29:01.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mTEST results: {'accuracy': 0.967, 'balanced_accuracy': 0.8279040945095137, 'sensitivity': 0.967, 'specificity': 0, 'precision': 0.9770417936237452, 'recall': 0.967, 'f1': 0.9700217737912542}\u001b[0m\n",
      " 25%|██▌       | 1/4 [00:06<00:18,  6.05s/it]\u001b[32m2024-02-16 11:29:01.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mTraining model with {'hidden_dim': 32, 'num_conv_layer': 3, 'num_linear_layers': 2, 'conv_type': 'transformer', 'pooling': 'mean', 'batch_size': 128, 'task_type': 'multiclass', 'dataset': 'ieee39'}\u001b[0m\n",
      "/root/anaconda3/envs/powergraph/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "\u001b[32m2024-02-16 11:29:01.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDataset characteristics: {'num_node_features': 3, 'num_edge_features': 4, 'num_classes': 4, 'unique_labels': [0, 1, 2, 3], 'counts': [72, 115, 48, 3065], 'dataset': 'ieee39'}\u001b[0m\n",
      "\u001b[32m2024-02-16 11:29:02.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mTEST results: {'accuracy': 0.9684848484848485, 'balanced_accuracy': 0.9693555147725214, 'sensitivity': 0.9684848484848485, 'specificity': 0, 'precision': 0.9808541039143212, 'recall': 0.9684848484848485, 'f1': 0.9723787293958798}\u001b[0m\n",
      " 50%|█████     | 2/4 [00:07<00:06,  3.10s/it]\u001b[32m2024-02-16 11:29:02.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mTraining model with {'hidden_dim': 32, 'num_conv_layer': 3, 'num_linear_layers': 2, 'conv_type': 'transformer', 'pooling': 'mean', 'batch_size': 128, 'task_type': 'binary', 'dataset': 'ieee118'}\u001b[0m\n",
      "/root/anaconda3/envs/powergraph/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "\u001b[32m2024-02-16 11:29:03.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDataset characteristics: {'num_node_features': 3, 'num_edge_features': 4, 'num_classes': 2, 'unique_labels': [0, 1], 'counts': [13813, 1187], 'dataset': 'ieee118'}\u001b[0m\n",
      "\u001b[32m2024-02-16 11:29:08.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mTP: 1179, TN: 13749, FP: 64, FN: 8\u001b[0m\n",
      "\u001b[32m2024-02-16 11:29:08.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mTEST results: {'accuracy': 0.9952, 'balanced_accuracy': 0.9943135018468798, 'sensitivity': 0.9932603201347936, 'specificity': 0.9953666835589662, 'precision': 0.9485116653258246, 'recall': 0.9932603201347936, 'f1': 0.9703703703703704, 'TP': 1179, 'TN': 13749, 'FP': 64, 'FN': 8}\u001b[0m\n",
      " 75%|███████▌  | 3/4 [00:13<00:04,  4.44s/it]\u001b[32m2024-02-16 11:29:08.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mTraining model with {'hidden_dim': 32, 'num_conv_layer': 3, 'num_linear_layers': 2, 'conv_type': 'transformer', 'pooling': 'mean', 'batch_size': 128, 'task_type': 'binary', 'dataset': 'ieee39'}\u001b[0m\n",
      "/root/anaconda3/envs/powergraph/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "\u001b[32m2024-02-16 11:29:08.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtest\u001b[0m:\u001b[36mrun_experiment\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mDataset characteristics: {'num_node_features': 3, 'num_edge_features': 4, 'num_classes': 2, 'unique_labels': [0, 1], 'counts': [3065, 235], 'dataset': 'ieee39'}\u001b[0m\n",
      "\u001b[32m2024-02-16 11:29:09.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mTP: 235, TN: 3034, FP: 31, FN: 0\u001b[0m\n",
      "\u001b[32m2024-02-16 11:29:09.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrainer\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mTEST results: {'accuracy': 0.9906060606060606, 'balanced_accuracy': 0.9949429037520392, 'sensitivity': 1.0, 'specificity': 0.9898858075040783, 'precision': 0.8834586466165414, 'recall': 1.0, 'f1': 0.93812375249501, 'TP': 235, 'TN': 3034, 'FP': 31, 'FN': 0}\u001b[0m\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>num_conv_layer</th>\n",
       "      <th>num_linear_layers</th>\n",
       "      <th>conv_type</th>\n",
       "      <th>pooling</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>task_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>transformer</td>\n",
       "      <td>mean</td>\n",
       "      <td>128</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>ieee118</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>transformer</td>\n",
       "      <td>mean</td>\n",
       "      <td>128</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>ieee39</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>transformer</td>\n",
       "      <td>mean</td>\n",
       "      <td>128</td>\n",
       "      <td>binary</td>\n",
       "      <td>ieee118</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.970</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>13749.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>transformer</td>\n",
       "      <td>mean</td>\n",
       "      <td>128</td>\n",
       "      <td>binary</td>\n",
       "      <td>ieee39</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.883</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.938</td>\n",
       "      <td>235.0</td>\n",
       "      <td>3034.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden_dim  num_conv_layer  num_linear_layers    conv_type pooling  \\\n",
       "0          32               3                  2  transformer    mean   \n",
       "1          32               3                  2  transformer    mean   \n",
       "2          32               3                  2  transformer    mean   \n",
       "3          32               3                  2  transformer    mean   \n",
       "\n",
       "   batch_size   task_type  dataset  accuracy  balanced_accuracy  sensitivity  \\\n",
       "0         128  multiclass  ieee118     0.967              0.828        0.967   \n",
       "1         128  multiclass   ieee39     0.968              0.969        0.968   \n",
       "2         128      binary  ieee118     0.995              0.994        0.993   \n",
       "3         128      binary   ieee39     0.991              0.995        1.000   \n",
       "\n",
       "   specificity  precision  recall     f1      TP       TN    FP   FN  \n",
       "0        0.000      0.977   0.967  0.970     NaN      NaN   NaN  NaN  \n",
       "1        0.000      0.981   0.968  0.972     NaN      NaN   NaN  NaN  \n",
       "2        0.995      0.949   0.993  0.970  1179.0  13749.0  64.0  8.0  \n",
       "3        0.990      0.883   1.000  0.938   235.0   3034.0  31.0  0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "number_of_iterations = 1\n",
    "hidden_dims = [32]\n",
    "num_conv_layers = [3]\n",
    "num_linear_layers = [2]\n",
    "conv_types = [ConvType.TRANSFORMER]\n",
    "task_types = [TaskType.MULTICLASS, TaskType.BINARY]\n",
    "dataset_types = [DatasetType.IEEE118, DatasetType.IEEE39]\n",
    "batch_sizes = [128]\n",
    "poolings = [PoolingType.MEAN]\n",
    "\n",
    "\n",
    "# Create a grid of all parameter combinations\n",
    "param_grid = product(hidden_dims, num_conv_layers, num_linear_layers, conv_types, poolings, task_types, dataset_types, batch_sizes)\n",
    "\n",
    "results = test.run_experiment(param_grid, number_of_iterations, debug=False)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "powergraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
